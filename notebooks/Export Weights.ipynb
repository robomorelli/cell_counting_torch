{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The goal here is to export the weights of the Keras model in a PyTorch-like state dictionary format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:23.265963Z",
     "start_time": "2021-11-25T13:38:22.230352Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers import Input, Dropout, Activation, Conv2D, MaxPooling2D, UpSampling2D, Lambda, BatchNormalization\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import callbacks, initializers, layers, models, optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:23.649406Z",
     "start_time": "2021-11-25T13:38:23.267449Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "repo_path = Path(\"..\")\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import visualization_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:23.670733Z",
     "start_time": "2021-11-25T13:38:23.650654Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model_name = \"c-ResUnet.h5\"\n",
    "# model_name = \"c-ResUnet_noWM.h5\"\n",
    "model_path = \"{}/model_results/{}\".format(repo_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:23.702615Z",
     "start_time": "2021-11-25T13:38:23.671833Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.2, 0.8, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "# dice loss\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\"Generate the 'Dice' coefficient for the provided prediction.\n",
    "    Args:\n",
    "        y_true: The expected/desired output mask.\n",
    "        y_pred: The actual/predicted mask.\n",
    "    Returns:\n",
    "        The Dice coefficient between the expected and actual outputs. Values\n",
    "        closer to 1 are considered 'better'.\n",
    "    \"\"\"\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \"\"\"Model loss function using the 'Dice' coefficient.\n",
    "    Args:\n",
    "        y_true: The expected/desired output mask.\n",
    "        y_pred: The actual/predicted mask.\n",
    "    Returns:\n",
    "        The corresponding loss, related to the dice coefficient between the expected\n",
    "        and actual outputs. Values closer to 0 are considered 'better'.\n",
    "    \"\"\"\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def create_weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "\n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "\n",
    "        b_ce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "        # Apply the weights\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_b_ce = weight_vector * b_ce\n",
    "\n",
    "        # Return the mean error\n",
    "        return K.mean(weighted_b_ce)\n",
    "\n",
    "    return weighted_binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:25.763807Z",
     "start_time": "2021-11-25T13:38:23.704153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/luca/anaconda3/envs/cc_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WeightedLoss = create_weighted_binary_crossentropy(1, 1.5)\n",
    "\n",
    "model = load_model(model_path, custom_objects={'mean_iou': mean_iou, 'dice_coef': dice_coef,\n",
    "                                               'weighted_binary_crossentropy': WeightedLoss}, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:25.797429Z",
     "start_time": "2021-11-25T13:38:25.764802Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 4           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 1 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 160         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 1 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 64          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 3 4640        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 3 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 3 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 3 9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 3 544         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 3 0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 3 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 3 128         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 3 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 18496       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 6 2112        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 6 0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 6 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 1 204928      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 1 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 1 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 1 409728      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 1 8320        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 1 0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 1 409728      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 1 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 1 409728      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 1 0           conv2d_14[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, None, None, 6 32832       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 1 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 1 512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 73792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 6 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 6 0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, None, None, 3 8224        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 6 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 256         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 3 18464       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 3 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 3 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 3 9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 3 0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, None, None, 1 2064        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 3 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 3 128         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 3 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 1 4624        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 1 64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 1 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 1 2320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 1 0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 17          add_7[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,709,177\n",
      "Trainable params: 1,707,287\n",
      "Non-trainable params: 1,890\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:25.888402Z",
     "start_time": "2021-11-25T13:38:25.799309Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_named_weights(model, shapes=False):\n",
    "    \"\"\"Return PyTorch's `state_dict`-like dictionary of model weights.\"\"\"\n",
    "    from collections import OrderedDict\n",
    "    names = [weight.name for layer in model.layers for weight in layer.weights]\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    state_dict = OrderedDict()\n",
    "    state_dict_shapes = OrderedDict()\n",
    "    for name, weight in zip(names, weights):\n",
    "        state_dict[name] = weight\n",
    "        if shapes:\n",
    "            state_dict_shapes[name] = weight.shape\n",
    "    return state_dict, state_dict_shapes\n",
    "\n",
    "\n",
    "state_dict, state_dict_shapes = get_named_weights(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:25.910529Z",
     "start_time": "2021-11-25T13:38:25.890060Z"
    }
   },
   "outputs": [],
   "source": [
    "# w = state_dict['conv2d_1/kernel:0']\n",
    "# for el in w.flatten():\n",
    "#     print(repr(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:39:50.867802Z",
     "start_time": "2021-11-25T13:39:50.824221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1/kernel:0 (1, 1, 3, 1)\n",
      "conv2d_1/bias:0 (1,)\n",
      "batch_normalization_1/gamma:0 (1,)\n",
      "batch_normalization_1/beta:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for k,v in state_dict_shapes.items():\n",
    "    print(k, v)\n",
    "    idx+=1\n",
    "    if idx==4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:25.961449Z",
     "start_time": "2021-11-25T13:38:25.939782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:\n",
      " [0.17005211] \n",
      "bias:\n",
      " [-0.03283687] \n",
      "mean:\n",
      " [0.2896597] \n",
      "variance:\n",
      " [7.10894e-05]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=20)\n",
    "\n",
    "# w_name = 'conv2d_1/kernel:0'\n",
    "w_name = 'batch_normalization_1'  # /beta:0'\n",
    "# w_name = 'conv2d_2'\n",
    "\n",
    "if 'conv' in w_name:\n",
    "    print('weight:\\n', state_dict[f\"{w_name}/kernel:0\"],\n",
    "          '\\nbias:\\n', state_dict[f\"{w_name}/bias:0\"])\n",
    "\n",
    "elif 'batch' in w_name:\n",
    "    print('weight:\\n', state_dict[f\"{w_name}/gamma:0\"],\n",
    "          '\\nbias:\\n', state_dict[f\"{w_name}/beta:0\"],\n",
    "          '\\nmean:\\n', state_dict[f\"{w_name}/moving_mean:0\"],\n",
    "          '\\nvariance:\\n', state_dict[f\"{w_name}/moving_variance:0\"])\n",
    "# state_dict[w_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:26.106127Z",
     "start_time": "2021-11-25T13:38:25.962519Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at: ../model_results/c-ResUnet_state_dict.pkl\n",
      "Saving at: ../model_results/c-ResUnet_state_dict_shapes.pkl\n",
      "saved dict:\n",
      " layer:\t conv2d_1/kernel:0 \tshape:\t (1, 1, 3, 1)\n",
      "loaded dict:\n",
      " layer:\t conv2d_1/kernel:0 \tshape:\t (1, 1, 3, 1)\n",
      "comparison:\n",
      "old: [[[[ 0.0028932514]\n",
      "   [-0.16237044  ]\n",
      "   [-0.0057095936]]]] \n",
      "new: [[[[ 0.0028932514]\n",
      "   [-0.16237044  ]\n",
      "   [-0.0057095936]]]]\n",
      "\n",
      "\n",
      "\n",
      "saved dict:\n",
      " layer:\t conv2d_1/bias:0 \tshape:\t (1,)\n",
      "loaded dict:\n",
      " layer:\t conv2d_1/bias:0 \tshape:\t (1,)\n",
      "comparison:\n",
      "old: [0.2927297] \n",
      "new: [0.2927297]\n",
      "\n",
      "\n",
      "\n",
      "saved dict:\n",
      " layer:\t batch_normalization_1/gamma:0 \tshape:\t (1,)\n",
      "loaded dict:\n",
      " layer:\t batch_normalization_1/gamma:0 \tshape:\t (1,)\n",
      "comparison:\n",
      "old: [0.17005211] \n",
      "new: [0.17005211]\n",
      "\n",
      "\n",
      "\n",
      "saved dict:\n",
      " layer:\t batch_normalization_1/beta:0 \tshape:\t (1,)\n",
      "loaded dict:\n",
      " layer:\t batch_normalization_1/beta:0 \tshape:\t (1,)\n",
      "comparison:\n",
      "old: [-0.03283687] \n",
      "new: [-0.03283687]\n",
      "\n",
      "\n",
      "\n",
      "saved dict:\n",
      " layer:\t batch_normalization_1/moving_mean:0 \tshape:\t (1,)\n",
      "loaded dict:\n",
      " layer:\t batch_normalization_1/moving_mean:0 \tshape:\t (1,)\n",
      "comparison:\n",
      "old: [0.2896597] \n",
      "new: [0.2896597]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def save_state_dict(d, path):\n",
    "    print('Saving at:', path)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(d, f)\n",
    "\n",
    "\n",
    "def load_state_dict(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        return d\n",
    "\n",
    "\n",
    "save_folder = f'{repo_path}/model_results/'\n",
    "\n",
    "# state_dict\n",
    "outpath = save_folder + f\"{model_name.split('.')[0]}_state_dict.pkl\"\n",
    "save_state_dict(state_dict, outpath)\n",
    "state_dict1 = load_state_dict(outpath)\n",
    "\n",
    "# state_dict_shapes\n",
    "outpath = save_folder + f\"{model_name.split('.')[0]}_state_dict_shapes.pkl\"\n",
    "save_state_dict(state_dict_shapes, outpath)\n",
    "state_dict_shapes1 = load_state_dict(outpath)\n",
    "\n",
    "idx = 0\n",
    "for old_w, old_s, new_w, new_s in zip(state_dict.keys(), state_dict_shapes.values(), state_dict1.keys(), state_dict_shapes1.values()):\n",
    "    print('saved dict:\\n', 'layer:\\t', old_w, '\\tshape:\\t', old_s)\n",
    "    print('loaded dict:\\n', 'layer:\\t', new_w, '\\tshape:\\t', new_s)\n",
    "    print('comparison:\\nold:', state_dict[old_w], '\\nnew:', state_dict1[new_w])\n",
    "    print('\\n\\n')\n",
    "    idx += 1\n",
    "    if idx > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:38:26.129276Z",
     "start_time": "2021-11-25T13:38:26.107315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model_results/c-ResUnet_state_dict_shapes.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "This correctly saves Keras weights as pickle files to be imported from PyTorch later.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
